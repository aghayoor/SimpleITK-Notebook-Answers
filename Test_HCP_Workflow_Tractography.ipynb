{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleITK Version: 0.9.1\n",
      "Compiled: Sep 28 2015 10:07:41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Boiler plate code common to many notebooks.  See the TestFilesCommonCode.ipynb for details\n",
    "from __future__ import print_function\n",
    "%run TestFilesCommonCode.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "#\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\n",
    "#####################################################################################\n",
    "#     Prepend the shell environment search paths\n",
    "PROGRAM_PATHS = '/scratch/NAMICExternalProjects/release-20160523/bin'\n",
    "#PROGRAM_PATHS = '/scratch/BS/release-BSR/bin'\n",
    "PROGRAM_PATHS = PROGRAM_PATHS.split(':')\n",
    "PROGRAM_PATHS.extend(os.environ['PATH'].split(':'))\n",
    "os.environ['PATH'] = ':'.join(PROGRAM_PATHS)\n",
    "\n",
    "CUSTOM_ENVIRONMENT=dict()\n",
    "\n",
    "# Platform specific information\n",
    "#     Prepend the python search paths\n",
    "#PYTHON_AUX_PATHS = '/scratch/BS/BRAINSTools/AutoWorkup'\n",
    "PYTHON_AUX_PATHS = '/scratch/SuperResolution/BRAINSSuperResolution/HCPWorkflows/:/scratch/wmql/tract_querier/tract_querier/nipype/'\n",
    "PYTHON_AUX_PATHS = PYTHON_AUX_PATHS.split(':')\n",
    "PYTHON_AUX_PATHS.extend(sys.path)\n",
    "sys.path = PYTHON_AUX_PATHS\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import nipype\n",
    "from nipype.interfaces.base import CommandLine, CommandLineInputSpec, TraitedSpec, File, Directory\n",
    "from nipype.interfaces.base import traits, isdefined, BaseInterface\n",
    "from nipype.interfaces.utility import Merge, Split, Function, Rename, IdentityInterface\n",
    "import nipype.interfaces.io as nio   # Data i/oS\n",
    "import nipype.pipeline.engine as pe  # pypeline engine\n",
    "from nipype.interfaces.freesurfer import ReconAll\n",
    "from nipype.interfaces.ants import DenoiseImage\n",
    "from nipype.interfaces.semtools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputLabelMap = '/Shared/sinapse/CACHE/20160610_HCP_base_Results/HCP_DATA/105115/HCP_105115_01/JointFusion/JointFusion_HDAtlas20_2015_fs_standard_label.nii.gz'\n",
    "DWI_brainMask = '/Volumes/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/HCPWorkflow_CACHE_105115/PreprocessingWorkflow_CACHE_105115/ResampleToAlignedDWIResolution/mapflow/_ResampleToAlignedDWIResolution2/DWIBrainMask.nrrd'\n",
    "DWI_Baseline = '/Volumes/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/HCPWorkflow_CACHE_105115/SuperResolutionWorkflow_CACHE_105115/runSR/DWI_Baseline.nrrd'\n",
    "DWI_SR_NN = '/Volumes/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/HCPWorkflow_CACHE_105115/SuperResolutionWorkflow_CACHE_105115/runSR/DWI_SR_NN.nrrd'\n",
    "DWI_SR_IFFT = '/Volumes/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/HCPWorkflow_CACHE_105115/SuperResolutionWorkflow_CACHE_105115/runSR/DWI_SR_IFFT.nrrd'\n",
    "DWI_SR_TV = '/Volumes/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/HCPWorkflow_CACHE_105115/SuperResolutionWorkflow_CACHE_105115/runSR/DWI_SR_TV.nrrd'\n",
    "DWI_SR_WTV = '/Volumes/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/HCPWorkflow_CACHE_105115/SuperResolutionWorkflow_CACHE_105115/runSR/DWI_SR_WTV.nrrd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sessionID = '105115'\n",
    "WFname = 'HCPWorkflow_Tractography_' + sessionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2a84cee18fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0mTractWF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m \u001b[0mTractWF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/IPLlinux/raid0/homes/aghayoor/anaconda/lib/python2.7/site-packages/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'write_provenance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/IPLlinux/raid0/homes/aghayoor/anaconda/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/IPLlinux/raid0/homes/aghayoor/anaconda/lib/python2.7/site-packages/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[0;34m(notrun)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***********************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[1;32m     96\u001b[0m                             'Check log for details'))\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "###### UTILITY FUNCTIONS #######\n",
    "#\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/#\n",
    "def MakeInputSRList(DWI_Baseline, DWI_SR_NN, DWI_SR_IFFT, DWI_SR_TV, DWI_SR_WTV):\n",
    "    imagesList = [DWI_Baseline, DWI_SR_NN, DWI_SR_IFFT, DWI_SR_TV, DWI_SR_WTV]\n",
    "    #imagesList = [DWI_Baseline, DWI_SR_WTV]\n",
    "    return imagesList\n",
    "\n",
    "def runWMQL(input_tractography, input_atlas):\n",
    "    import os\n",
    "    from wmql import TractQuerier\n",
    "    # prepare proper prefix\n",
    "    sr_file_name = os.path.basename(input_tractography)\n",
    "    sr_file_name_base = os.path.splitext(sr_file_name)[0]\n",
    "    sr_name = sr_file_name_base.split('_',1)[0]\n",
    "    out_prefix = sr_name + '_query'\n",
    "    # run WMQL\n",
    "    tract_querier = TractQuerier()\n",
    "    tract_querier.inputs.input_atlas = input_atlas\n",
    "    tract_querier.inputs.input_tractography = input_tractography\n",
    "    tract_querier.inputs.out_prefix = out_prefix\n",
    "    tract_querier.inputs.queries = ['cst.left' ,'cst.right']\n",
    "    tract_querier.run()\n",
    "    # check outputs\n",
    "    output_cst_left_name = out_prefix + '_' + 'cst.left.vtp'\n",
    "    output_cst_right_name = out_prefix + '_' + 'cst.right.vtp'\n",
    "    output_cst_left = os.path.join(os.getcwd(), output_cst_left_name)\n",
    "    output_cst_right = os.path.join(os.getcwd(), output_cst_right_name)\n",
    "    assert os.path.isfile(output_cst_left), \"Output cst tract file is not found: %s\" % output_cst_left\n",
    "    assert os.path.isfile(output_cst_right), \"Output cst tract file is not found: %s\" % output_cst_right\n",
    "    return [output_cst_left,output_cst_right]\n",
    "\n",
    "# This function helps to pick desirable output from the output list\n",
    "def pickFromList(inlist,item):\n",
    "    return inlist[item]\n",
    "    \n",
    "def MakeInputCSTList(NN_cst, IFFT_cst, TV_cst, WTV_cst):\n",
    "    outputList = [NN_cst, IFFT_cst, TV_cst, WTV_cst]\n",
    "    return outputList\n",
    "\n",
    "def CSTOverlap(gs_cst_left, gs_cst_right, sr_cst_left, sr_cst_right):\n",
    "    import os\n",
    "    def ComputeBhattacharyyaCoeficient(baseline_bundle, sr_bundle):\n",
    "        # read in each fiber bundle\n",
    "        # gs: gold standard, sr: super-resolution reconstructed\n",
    "        import vtk\n",
    "        import numpy as np\n",
    "        ##\n",
    "        def ReturnDistributionInEachCoordinate(bundle):\n",
    "            from scipy import stats\n",
    "            numPoints = bundle.GetNumberOfPoints()\n",
    "            points = bundle.GetPoints()\n",
    "            x_arr = np.array([points.GetPoint(i)[0] for i in xrange(numPoints)])\n",
    "            y_arr = np.array([points.GetPoint(i)[1] for i in xrange(numPoints)])\n",
    "            z_arr = np.array([points.GetPoint(i)[2] for i in xrange(numPoints)])\n",
    "            x = np.linspace(x_arr.min(), x_arr.max(), 100)\n",
    "            y = np.linspace(y_arr.min(), y_arr.max(), 100)\n",
    "            z = np.linspace(z_arr.min(), z_arr.max(), 100)\n",
    "            kde_x = stats.gaussian_kde(x_arr)\n",
    "            kde_y = stats.gaussian_kde(y_arr)\n",
    "            kde_z = stats.gaussian_kde(z_arr)\n",
    "            p_x = kde_x(x)\n",
    "            p_y = kde_y(y)\n",
    "            p_z = kde_z(z)\n",
    "            return p_x, p_y, p_z\n",
    "        ## read in each fiber bundle\n",
    "        reader_gs = vtk.vtkXMLPolyDataReader()\n",
    "        reader_gs.SetFileName(baseline_bundle)\n",
    "        reader_gs.Update()\n",
    "        gs = reader_gs.GetOutput()\n",
    "        #\n",
    "        reader_sr = vtk.vtkXMLPolyDataReader()\n",
    "        reader_sr.SetFileName(sr_bundle)\n",
    "        reader_sr.Update()\n",
    "        sr = reader_sr.GetOutput()\n",
    "        ## Use ksdensity to estimate probability density function for the sample data in each coordinate\n",
    "        [p_gs_x, p_gs_y, p_gs_z] = ReturnDistributionInEachCoordinate(gs)\n",
    "        [p_sr_x, p_sr_y, p_sr_z] = ReturnDistributionInEachCoordinate(sr)\n",
    "        BC = (1.0/3.0)*( np.sum(np.sqrt(p_gs_x * p_sr_x)) + np.sum(np.sqrt(p_gs_y * p_sr_y)) + np.sum(np.sqrt(p_gs_z * p_sr_z)) )\n",
    "        return BC\n",
    "        ##\n",
    "    def writeLabelStatistics(filename,statsList):\n",
    "        import csv\n",
    "        label = os.path.splitext(os.path.basename(filename))[0]\n",
    "        with open(filename, 'wb') as lf:\n",
    "            headerdata = [['#Label', 'BC_left.cst', 'BC_right.cst', 'BC_cst']]\n",
    "            wr = csv.writer(lf, delimiter=',')\n",
    "            wr.writerows(headerdata)\n",
    "            wr.writerows([[label] + statsList])\n",
    "        ###\n",
    "    # compute Bhattacharyya Coeficient for cst.left/right/total\n",
    "    bc_l = ComputeBhattacharyyaCoeficient(gs_cst_left,sr_cst_left)\n",
    "    if bc_l > 1: bc_l = 1\n",
    "    bc_r = ComputeBhattacharyyaCoeficient(gs_cst_right,sr_cst_right)\n",
    "    if bc_r > 1: bc_r = 1\n",
    "    bc_total = (bc_l + bc_r)/2.0\n",
    "    statsList = [format(bc_l,'.4f'), format(bc_r,'.4f'), format(bc_total,'.4f')]\n",
    "    # create output file name\n",
    "    srfn = os.path.basename(sr_cst_left)\n",
    "    srfnbase = os.path.splitext(srfn)[0]\n",
    "    srLabel = srfnbase.split('_',1)[0]\n",
    "    fn = srLabel + '.csv'\n",
    "    output_csv_file = os.path.join(os.getcwd(), fn)\n",
    "    # write the stats list\n",
    "    writeLabelStatistics(output_csv_file,statsList)\n",
    "    assert os.path.isfile(output_csv_file), \"Output Bhattacharyya coeficient file is not found: %s\" % output_csv_file\n",
    "    return output_csv_file\n",
    "#################################\n",
    "#\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\#\n",
    "\n",
    "TractWF = pe.Workflow(name=WFname)\n",
    "\n",
    "BASE_DIR = os.path.join('/scratch/TESTS/IpythonNotebook/20160615_HCPWF', '4_tractographyWF')\n",
    "TractWF.base_dir = BASE_DIR\n",
    "\n",
    "inputsSpec = pe.Node(interface=IdentityInterface(fields=['inputLabelMap',\n",
    "                                                         'DWI_brainMask',\n",
    "                                                         'DWI_Baseline',\n",
    "                                                         'DWI_SR_NN',\n",
    "                                                         'DWI_SR_IFFT',\n",
    "                                                         'DWI_SR_TV',\n",
    "                                                         'DWI_SR_WTV',\n",
    "                                                         ]),\n",
    "                      name='inputsSpec')\n",
    "\n",
    "inputsSpec.inputs.inputLabelMap = inputLabelMap\n",
    "inputsSpec.inputs.DWI_brainMask = DWI_brainMask\n",
    "inputsSpec.inputs.DWI_Baseline = DWI_Baseline\n",
    "inputsSpec.inputs.DWI_SR_NN = DWI_SR_NN\n",
    "inputsSpec.inputs.DWI_SR_IFFT = DWI_SR_IFFT\n",
    "inputsSpec.inputs.DWI_SR_TV = DWI_SR_TV\n",
    "inputsSpec.inputs.DWI_SR_WTV = DWI_SR_WTV\n",
    "\n",
    "outputsSpec = pe.Node(interface=IdentityInterface(fields=['Baseline_ukfTracts',\n",
    "                                                          'NN_ukfTracts',\n",
    "                                                          'IFFT_ukfTracts',\n",
    "                                                          'TV_ukfTracts',\n",
    "                                                          'WTV_ukfTracts',\n",
    "                                                          'Baseline_cst_left','Baseline_cst_right',\n",
    "                                                          'NN_cst_left','NN_cst_right',\n",
    "                                                          'IFFT_cst_left','IFFT_cst_right',\n",
    "                                                          'TV_cst_left','TV_cst_right',\n",
    "                                                          'WTV_cst_left','WTV_cst_right',\n",
    "                                                          'NN_overlap_coeficient',\n",
    "                                                          'IFFT_overlap_coeficient',\n",
    "                                                          'TV_overlap_coeficient',\n",
    "                                                          'WTV_overlap_coeficient'\n",
    "                                                         ]),\n",
    "                      name='outputsSpec')\n",
    "\n",
    "##\n",
    "## Step 1: Create input list\n",
    "##\n",
    "MakeInputSRListNode = pe.Node(Function(function=MakeInputSRList,\n",
    "                                       input_names=['DWI_Baseline','DWI_SR_NN','DWI_SR_IFFT','DWI_SR_TV','DWI_SR_WTV'],\n",
    "                                       output_names=['imagesList']),\n",
    "                              name=\"MakeInputSRList\")\n",
    "TractWF.connect([(inputsSpec,MakeInputSRListNode,[('DWI_Baseline','DWI_Baseline'),\n",
    "                                                  ('DWI_SR_NN','DWI_SR_NN'),\n",
    "                                                  ('DWI_SR_IFFT','DWI_SR_IFFT'),\n",
    "                                                  ('DWI_SR_TV','DWI_SR_TV'),\n",
    "                                                  ('DWI_SR_WTV','DWI_SR_WTV')\n",
    "                                                 ])])\n",
    "\n",
    "##\n",
    "## Step 2: UKF Processing\n",
    "##\n",
    "UKFNode = pe.MapNode(interface=UKFTractography(), name= \"RunUKFt\", iterfield=['dwiFile','tracts'])\n",
    "UKFNode.inputs.tracts = ['Baseline_ukfTracts.vtp','NN_ukfTracts.vtp','IFFT_ukfTracts.vtp','TV_ukfTracts.vtp','WTV_ukfTracts.vtp']\n",
    "UKFNode.inputs.numTensor = '2'\n",
    "UKFNode.inputs.freeWater = True ## default False\n",
    "UKFNode.inputs.minFA = 0.15\n",
    "UKFNode.inputs.minGA = 0.15\n",
    "UKFNode.inputs.seedFALimit = 0.06\n",
    "UKFNode.inputs.Ql = 70\n",
    "UKFNode.inputs.Rs = 0.025\n",
    "UKFNode.inputs.recordLength = 1.25\n",
    "UKFNode.inputs.recordTensors = True\n",
    "UKFNode.inputs.recordFreeWater = True\n",
    "UKFNode.inputs.recordFA = True\n",
    "UKFNode.inputs.recordTrace = True\n",
    "UKFNode.inputs.seedsPerVoxel = 1\n",
    "TractWF.connect(MakeInputSRListNode, 'imagesList', UKFNode, 'dwiFile')\n",
    "TractWF.connect(inputsSpec, 'DWI_brainMask', UKFNode, 'maskFile')\n",
    "TractWF.connect(UKFNode,('tracts', pickFromList, 0),outputsSpec,'Baseline_ukfTracts')\n",
    "TractWF.connect(UKFNode,('tracts', pickFromList, 1),outputsSpec,'NN_ukfTracts')\n",
    "TractWF.connect(UKFNode,('tracts', pickFromList, 2),outputsSpec,'IFFT_ukfTracts')\n",
    "TractWF.connect(UKFNode,('tracts', pickFromList, 3),outputsSpec,'TV_ukfTracts')\n",
    "TractWF.connect(UKFNode,('tracts', pickFromList, 4),outputsSpec,'WTV_ukfTracts')\n",
    "\n",
    "##\n",
    "## Step 3: run WMQL to extract cortico-spinal (CST) tract bundles\n",
    "##\n",
    "tract_querier = pe.MapNode(interface=Function(function = runWMQL,\n",
    "                                              input_names=['input_tractography','input_atlas'],\n",
    "                                              output_names=['output_cst_left','output_cst_right']),\n",
    "                            name=\"tract_querier\", iterfield=['input_tractography'])\n",
    "TractWF.connect(UKFNode,'tracts',tract_querier,'input_tractography')\n",
    "TractWF.connect(inputsSpec,'inputLabelMap',tract_querier,'input_atlas')\n",
    "# baseline cst\n",
    "TractWF.connect(tract_querier,('output_cst_left', pickFromList, 0),outputsSpec,'Baseline_cst_left')\n",
    "TractWF.connect(tract_querier,('output_cst_right', pickFromList, 0),outputsSpec,'Baseline_cst_right')\n",
    "# NN cst\n",
    "TractWF.connect(tract_querier,('output_cst_left', pickFromList, 1),outputsSpec,'NN_cst_left')\n",
    "TractWF.connect(tract_querier,('output_cst_right', pickFromList, 1),outputsSpec,'NN_cst_right')\n",
    "# IFFT cst\n",
    "TractWF.connect(tract_querier,('output_cst_left', pickFromList, 2),outputsSpec,'IFFT_cst_left')\n",
    "TractWF.connect(tract_querier,('output_cst_right', pickFromList, 2),outputsSpec,'IFFT_cst_right')\n",
    "# TV cst\n",
    "TractWF.connect(tract_querier,('output_cst_left', pickFromList, 3),outputsSpec,'TV_cst_left')\n",
    "TractWF.connect(tract_querier,('output_cst_right', pickFromList, 3),outputsSpec,'TV_cst_right')\n",
    "# WTV cst\n",
    "TractWF.connect(tract_querier,('output_cst_left', pickFromList, 4),outputsSpec,'WTV_cst_left')\n",
    "TractWF.connect(tract_querier,('output_cst_right', pickFromList, 4),outputsSpec,'WTV_cst_right')\n",
    "\n",
    "##\n",
    "## Step 4: Make SR CST left/right lists\n",
    "##\n",
    "\n",
    "# step 4_1: input cst.left\n",
    "cst_left_list = pe.Node(Function(function=MakeInputCSTList,\n",
    "                                 input_names=['NN_cst', 'IFFT_cst', 'TV_cst', 'WTV_cst'],\n",
    "                                 output_names=['outputList']),\n",
    "                        name=\"cst_left_list\")\n",
    "TractWF.connect([(tract_querier,cst_left_list,[(('output_cst_left', pickFromList, 1),'NN_cst'),\n",
    "                                               (('output_cst_left', pickFromList, 2),'IFFT_cst'),\n",
    "                                               (('output_cst_left', pickFromList, 3),'TV_cst'),\n",
    "                                               (('output_cst_left', pickFromList, 4),'WTV_cst')\n",
    "                                              ])])\n",
    "\n",
    "# step 4_2: input cst.right\n",
    "cst_right_list = pe.Node(Function(function=MakeInputCSTList,\n",
    "                                  input_names=['NN_cst', 'IFFT_cst', 'TV_cst', 'WTV_cst'],\n",
    "                                  output_names=['outputList']),\n",
    "                        name=\"cst_right_list\")\n",
    "TractWF.connect([(tract_querier,cst_right_list,[(('output_cst_right', pickFromList, 1),'NN_cst'),\n",
    "                                                (('output_cst_right', pickFromList, 2),'IFFT_cst'),\n",
    "                                                (('output_cst_right', pickFromList, 3),'TV_cst'),\n",
    "                                                (('output_cst_right', pickFromList, 4),'WTV_cst')\n",
    "                                              ])])\n",
    "\n",
    "#\n",
    "# Step 5: Compute Bhattacharyya coeficient to find overlap between CST tract bundles\n",
    "#\n",
    "cst_overlap = pe.MapNode(interface=Function(function = CSTOverlap,\n",
    "                                            input_names=['gs_cst_left', 'gs_cst_right', 'sr_cst_left', 'sr_cst_right'],\n",
    "                                            output_names=['output_csv_file']),\n",
    "                         name=\"BhattacharyyaCoeficient\", iterfield=['sr_cst_left','sr_cst_right'])\n",
    "TractWF.connect(tract_querier,('output_cst_left', pickFromList, 0),cst_overlap,'gs_cst_left')\n",
    "TractWF.connect(tract_querier,('output_cst_right', pickFromList, 0),cst_overlap,'gs_cst_right')\n",
    "TractWF.connect(cst_left_list,'outputList',cst_overlap,'sr_cst_left')\n",
    "TractWF.connect(cst_right_list,'outputList',cst_overlap,'sr_cst_right')\n",
    "TractWF.connect(cst_overlap, ('output_csv_file', pickFromList, 0), outputsSpec, 'NN_overlap_coeficient')\n",
    "TractWF.connect(cst_overlap, ('output_csv_file', pickFromList, 1), outputsSpec, 'IFFT_overlap_coeficient')\n",
    "TractWF.connect(cst_overlap, ('output_csv_file', pickFromList, 2), outputsSpec, 'TV_overlap_coeficient')\n",
    "TractWF.connect(cst_overlap, ('output_csv_file', pickFromList, 3), outputsSpec, 'WTV_overlap_coeficient')\n",
    "\n",
    "######## DATA Sink\n",
    "DWIDataSink = pe.Node(interface=nio.DataSink(), name='DWIDataSink')\n",
    "DWIDataSink.overwrite = True\n",
    "DWIDataSink.inputs.base_directory = BASE_DIR\n",
    "DWIDataSink.inputs.base_directory = BASE_DIR\n",
    "DWIDataSink.inputs.substitutions = [('Outputs/Tractography/_RunUKFt0/','Outputs/Tractography/'),\n",
    "                                    ('Outputs/Tractography/_RunUKFt1/','Outputs/Tractography/'),\n",
    "                                    ('Outputs/Tractography/_RunUKFt2/','Outputs/Tractography/'),\n",
    "                                    ('Outputs/Tractography/_RunUKFt3/','Outputs/Tractography/'),\n",
    "                                    ('Outputs/Tractography/_RunUKFt4/','Outputs/Tractography/'),\n",
    "                                    ('Outputs/WMQL/_tract_querier0/','Outputs/WMQL/'),\n",
    "                                    ('Outputs/WMQL/_tract_querier1/','Outputs/WMQL/'),\n",
    "                                    ('Outputs/WMQL/_tract_querier2/','Outputs/WMQL/'),\n",
    "                                    ('Outputs/WMQL/_tract_querier3/','Outputs/WMQL/'),\n",
    "                                    ('Outputs/WMQL/_tract_querier4/','Outputs/WMQL/'),\n",
    "                                    ('Outputs/Stats/_BhattacharyyaCoeficient0/','Outputs/Stats/'),\n",
    "                                    ('Outputs/Stats/_BhattacharyyaCoeficient1/','Outputs/Stats/'),\n",
    "                                    ('Outputs/Stats/_BhattacharyyaCoeficient2/','Outputs/Stats/'),\n",
    "                                    ('Outputs/Stats/_BhattacharyyaCoeficient3/','Outputs/Stats/')\n",
    "                                   ]\n",
    "\n",
    "TractWF.connect(outputsSpec, 'Baseline_ukfTracts', DWIDataSink, 'Outputs.Tractography.@Baseline_ukfTracts')\n",
    "TractWF.connect(outputsSpec, 'NN_ukfTracts', DWIDataSink, 'Outputs.Tractography.@NN_ukfTracts')\n",
    "TractWF.connect(outputsSpec, 'IFFT_ukfTracts', DWIDataSink, 'Outputs.Tractography.@IFFT_ukfTracts')\n",
    "TractWF.connect(outputsSpec, 'TV_ukfTracts', DWIDataSink, 'Outputs.Tractography.@TV_ukfTracts')\n",
    "TractWF.connect(outputsSpec, 'WTV_ukfTracts', DWIDataSink, 'Outputs.Tractography.@WTV_ukfTracts')\n",
    "TractWF.connect(outputsSpec, 'Baseline_cst_left', DWIDataSink, 'Outputs.WMQL.@Baseline_cst_left')\n",
    "TractWF.connect(outputsSpec, 'Baseline_cst_right', DWIDataSink, 'Outputs.WMQL.@Baseline_cst_right')\n",
    "TractWF.connect(outputsSpec, 'NN_cst_left', DWIDataSink, 'Outputs.WMQL.@NN_cst_left')\n",
    "TractWF.connect(outputsSpec, 'NN_cst_right', DWIDataSink, 'Outputs.WMQL.@NN_cst_right')\n",
    "TractWF.connect(outputsSpec, 'IFFT_cst_left', DWIDataSink, 'Outputs.WMQL.@IFFT_cst_left')\n",
    "TractWF.connect(outputsSpec, 'IFFT_cst_right', DWIDataSink, 'Outputs.WMQL.@IFFT_cst_right')\n",
    "TractWF.connect(outputsSpec, 'TV_cst_left', DWIDataSink, 'Outputs.WMQL.@TV_cst_left')\n",
    "TractWF.connect(outputsSpec, 'TV_cst_right', DWIDataSink, 'Outputs.WMQL.@TV_cst_right')\n",
    "TractWF.connect(outputsSpec, 'WTV_cst_left', DWIDataSink, 'Outputs.WMQL.@WTV_cst_left')\n",
    "TractWF.connect(outputsSpec, 'WTV_cst_right', DWIDataSink, 'Outputs.WMQL.@WTV_cst_right')\n",
    "TractWF.connect(outputsSpec, 'NN_overlap_coeficient', DWIDataSink, 'Outputs.Stats.@NN_overlap_coeficient')\n",
    "TractWF.connect(outputsSpec, 'IFFT_overlap_coeficient', DWIDataSink, 'Outputs.Stats.@IFFT_overlap_coeficient')\n",
    "TractWF.connect(outputsSpec, 'TV_overlap_coeficient', DWIDataSink, 'Outputs.Stats.@TV_overlap_coeficient')\n",
    "TractWF.connect(outputsSpec, 'WTV_overlap_coeficient', DWIDataSink, 'Outputs.Stats.@WTV_overlap_coeficient')\n",
    "#\n",
    "\n",
    "TractWF.write_graph()\n",
    "TractWF.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
