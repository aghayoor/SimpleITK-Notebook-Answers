{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleITK Version: 0.9.1\n",
      "Compiled: Sep 28 2015 10:07:41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Boiler plate code common to many notebooks.  See the TestFilesCommonCode.ipynb for details\n",
    "from __future__ import print_function\n",
    "%run TestFilesCommonCode.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "#\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\n",
    "#####################################################################################\n",
    "#     Prepend the shell environment search paths\n",
    "PROGRAM_PATHS = '/scratch/NAMICExternalProjects/release-20160523/bin'\n",
    "#PROGRAM_PATHS = '/scratch/BS/release-BSR/bin'\n",
    "PROGRAM_PATHS = PROGRAM_PATHS.split(':')\n",
    "PROGRAM_PATHS.extend(os.environ['PATH'].split(':'))\n",
    "os.environ['PATH'] = ':'.join(PROGRAM_PATHS)\n",
    "\n",
    "CUSTOM_ENVIRONMENT=dict()\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import nipype\n",
    "from nipype.interfaces.base import CommandLine, CommandLineInputSpec, TraitedSpec, File, Directory\n",
    "from nipype.interfaces.base import traits, isdefined, BaseInterface\n",
    "from nipype.interfaces.utility import Merge, Split, Function, Rename, IdentityInterface\n",
    "import nipype.interfaces.io as nio   # Data i/oS\n",
    "import nipype.pipeline.engine as pe  # pypeline engine\n",
    "from nipype.interfaces.freesurfer import ReconAll\n",
    "from nipype.interfaces.ants import DenoiseImage\n",
    "from nipype.interfaces.semtools import *\n",
    "\n",
    "# Platform specific information\n",
    "#     Prepend the python search paths\n",
    "#PYTHON_AUX_PATHS = '/scratch/BS/BRAINSTools/AutoWorkup'\n",
    "PYTHON_AUX_PATHS = '/scratch/SuperResolution/BRAINSSuperResolution/HCPWorkflows/:/scratch/wmql/tract_querier/tract_querier/'\n",
    "PYTHON_AUX_PATHS = PYTHON_AUX_PATHS.split(':')\n",
    "PYTHON_AUX_PATHS.extend(sys.path)\n",
    "sys.path = PYTHON_AUX_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tract_querier.nipype.wmql import TractQuerier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gs: gold standard\n",
    "# in: input\n",
    "# gs_cst_left_fn = '/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/Outputs_July27/WMQL/Baseline_query_cst.left.vtp'\n",
    "# gs_cst_right_fn = '/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/Outputs_July27/WMQL/Baseline_query_cst.right.vtp'\n",
    "\n",
    "# sr_cst_left_fn = '/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/Outputs_July27/WMQL/WTV_query_cst.left.vtp'\n",
    "# sr_cst_right_fn = '/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/Outputs_July27/WMQL/WTV_query_cst.right.vtp'\n",
    "\n",
    "gs_cst_left_fn = '/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/test_wmql/July31/Baseline_query_cst.left.vtp'\n",
    "gs_cst_right_fn = '/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/test_wmql/July31/Baseline_query_cst.right.vtp'\n",
    "\n",
    "sr_cst_left_fn = '/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/test_wmql/July31/IFFT_query_cst.left.vtp'\n",
    "sr_cst_right_fn = '/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/test_wmql/July31/IFFT_query_cst.right.vtp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CSTOverlap(gs_cst_left, gs_cst_right, sr_cst_left, sr_cst_right):\n",
    "    # gs: gold standard, sr: super-resolution reconstructed\n",
    "    import os\n",
    "    #########\n",
    "    def ComputeBhattacharyyaCoeficient(gs_bundle,sr_bundle):\n",
    "        from tract_querier import tract_math, tractography\n",
    "        import numpy as np\n",
    "        ###\n",
    "        def AlignFiber(tract):\n",
    "            out_tract = tract\n",
    "            vecs = np.diff(tract, axis=0)\n",
    "            avg_vec = np.mean(vecs, axis=0)\n",
    "            dots = np.array([ np.dot(avg_vec,[1,0,0]), np.dot(avg_vec,[0,1,0]), np.dot(avg_vec,[0,0,1]) ])\n",
    "            idx = np.argmax(np.abs(dots))\n",
    "            if (dots[idx] < 0):\n",
    "                out_tract = tract[::-1]\n",
    "            return out_tract\n",
    "        #\n",
    "        def InterpolateFiber(tract):\n",
    "            new_tract = tract\n",
    "            # find point distances\n",
    "            d = np.diff(tract, axis=0)\n",
    "            pointdists = np.hypot(d[:,0], d[:,1], d[:,2])\n",
    "            dist_threshold = min(pointdists.sum()/len(pointdists),1)\n",
    "            offset = 0\n",
    "            for i in xrange(len(pointdists)):\n",
    "                if pointdists[i] > dist_threshold:\n",
    "                    new_p = (tract[i+1]+tract[i])/2\n",
    "                    new_tract = np.insert(new_tract,i+1+offset,new_p,axis=0)\n",
    "                    offset += 1\n",
    "            return new_tract\n",
    "        #\n",
    "        def returnBundlePoints(bundle):\n",
    "            in_tractography = tractography.tractography_from_files(bundle)\n",
    "            tracts = in_tractography.tracts()\n",
    "            ## sort all tracts direction to positive coordinate of their dominant orientation\n",
    "            ## then interpolate tracts to make sure they are approximately equally placed\n",
    "            for i in xrange(len(tracts)):\n",
    "                tracts[i] = AlignFiber(tracts[i])\n",
    "                tracts[i] = InterpolateFiber(tracts[i])\n",
    "            #\n",
    "            tracts_last_quarter = [tracts[i][4*len(tracts[i])/5:] for i in xrange(len(tracts))]\n",
    "            #\n",
    "            pts = np.vstack(tracts)\n",
    "            pts_last_quarter = np.vstack(tracts_last_quarter)\n",
    "            return pts, pts_last_quarter\n",
    "        #\n",
    "        def returnBhattCoef(gs_pts,sr_pts):\n",
    "            from scipy import stats\n",
    "            gs_xyz = np.array([np.linspace(gs_pts.min(0)[i],gs_pts.max(0)[i],100) for i in xrange(3)])\n",
    "            sr_xyz = np.array([np.linspace(sr_pts.min(0)[i],sr_pts.max(0)[i],100) for i in xrange(3)])\n",
    "            #\n",
    "            gs_kde = np.array([ stats.gaussian_kde(gs_pts[:,i]) for i in xrange(3) ])\n",
    "            gs_p = np.array([ gs_kde[i](gs_xyz[i]) for i in xrange(3) ])\n",
    "            gs_p = np.array([gs_p[i]/gs_p.sum(1)[i] for i in xrange(3)])\n",
    "            #\n",
    "            sr_kde = np.array([ stats.gaussian_kde(sr_pts[:,i]) for i in xrange(3) ])\n",
    "            sr_p = np.array([ sr_kde[i](sr_xyz[i]) for i in xrange(3) ])\n",
    "            sr_p = np.array([sr_p[i]/sr_p.sum(1)[i] for i in xrange(3)])\n",
    "            #\n",
    "            coefs = np.array([ np.sqrt(gs_p[i]*sr_p[i]).sum() for i in xrange(3) ]) \n",
    "            return coefs.mean()\n",
    "        ###\n",
    "        [gs_pts, gs_pts_last_quarter] = returnBundlePoints(gs_bundle)\n",
    "        [sr_pts, sr_pts_last_quarter] = returnBundlePoints(sr_bundle)\n",
    "        #\n",
    "        coef = returnBhattCoef(gs_pts,sr_pts)\n",
    "        coef_last_quarter = returnBhattCoef(gs_pts_last_quarter,sr_pts_last_quarter)\n",
    "        return [coef,coef_last_quarter] \n",
    "    #########\n",
    "    def writeLabelStatistics(filename,statsList):\n",
    "        import csv\n",
    "        label = os.path.splitext(os.path.basename(filename))[0].split('_',1)[0]\n",
    "        with open(filename, 'wb') as lf:\n",
    "            headerdata = [['#Label', 'cst_left', 'cst_right', 'cst', 'cst_left_top', 'cst_right_top', 'cst_top']]\n",
    "            wr = csv.writer(lf, delimiter=',')\n",
    "            wr.writerows(headerdata)\n",
    "            wr.writerows([[label] + statsList])\n",
    "    #########\n",
    "    # compute Bhattacharyya Coeficient for cst.left/right/total\n",
    "    bc_l,bc_l_q = ComputeBhattacharyyaCoeficient(gs_cst_left,sr_cst_left)\n",
    "    bc_r,bc_r_q = ComputeBhattacharyyaCoeficient(gs_cst_right,sr_cst_right)\n",
    "    bc_total = (bc_l + bc_r)/2.0\n",
    "    bc_total_q = (bc_l_q + bc_r_q)/2.0\n",
    "    statsList = [format(bc_l,'.4f'), format(bc_r,'.4f'), format(bc_total,'.4f'), format(bc_l_q,'.4f'), format(bc_r_q,'.4f'), format(bc_total_q,'.4f')]\n",
    "    # create output file name\n",
    "    srfn = os.path.basename(sr_cst_left)\n",
    "    srfnbase = os.path.splitext(srfn)[0]\n",
    "    srLabel = srfnbase.split('_',1)[0]\n",
    "    fn = srLabel + '_BhattacharyyaCoeficient.csv'\n",
    "    output_csv_file = os.path.join(os.getcwd(), fn)\n",
    "    # write the stats list\n",
    "    writeLabelStatistics(output_csv_file,statsList)\n",
    "    assert os.path.isfile(output_csv_file), \"Output Bhattacharyya coeficient file is not found: %s\" % output_csv_file\n",
    "    return output_csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = CSTOverlap(gs_cst_left_fn, gs_cst_right_fn, sr_cst_left_fn, sr_cst_right_fn)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare FA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tract_querier import tract_math, tractography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bundle = gs_cst_left_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_tractography = tractography.tractography_from_files(bundle)\n",
    "tracts = in_tractography.tracts()\n",
    "tracts_data = in_tractography.tracts_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in tracts_data:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FA1 = tracts_data['FA1']\n",
    "print(len(FA1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tract_querier import tract_math, tractography\n",
    "import numpy as np\n",
    "###\n",
    "def AlignFiber(tract):\n",
    "    out_tract = tract\n",
    "    vecs = np.diff(tract, axis=0)\n",
    "    avg_vec = np.mean(vecs, axis=0)\n",
    "    dots = np.array([ np.dot(avg_vec,[1,0,0]), np.dot(avg_vec,[0,1,0]), np.dot(avg_vec,[0,0,1]) ])\n",
    "    idx = np.argmax(np.abs(dots))\n",
    "    if (dots[idx] < 0):\n",
    "    #if (dots[2] < 0):\n",
    "        out_tract = tract[::-1]\n",
    "    return out_tract\n",
    "#\n",
    "def InterpolateFiber(tract):\n",
    "    new_tract = tract\n",
    "    # find point distances\n",
    "    d = np.diff(tract, axis=0)\n",
    "    pointdists = np.hypot(d[:,0], d[:,1], d[:,2])\n",
    "    dist_threshold = min(pointdists.sum()/len(pointdists),1)\n",
    "    offset = 0\n",
    "    for i in xrange(len(pointdists)):\n",
    "        if pointdists[i] > dist_threshold:\n",
    "            new_p = (tract[i+1]+tract[i])/2\n",
    "            new_tract = np.insert(new_tract,i+1+offset,new_p,axis=0)\n",
    "            offset += 1\n",
    "    return new_tract\n",
    "#\n",
    "def returnBundlePoints(bundle):\n",
    "    in_tractography = tractography.tractography_from_files(bundle)\n",
    "    tracts = in_tractography.tracts()\n",
    "    ## sort all tracts direction to positive coordinate of their dominant orientation\n",
    "    ## then interpolate tracts to make sure they are approximately equally placed\n",
    "    for i in xrange(len(tracts)):\n",
    "        tracts[i] = AlignFiber(tracts[i])\n",
    "        tracts[i] = InterpolateFiber(tracts[i])\n",
    "    #\n",
    "    tracts_last_quarter = [tracts[i][4*len(tracts[i])/5:] for i in xrange(len(tracts))]\n",
    "    #\n",
    "    pts = np.vstack(tracts)\n",
    "    pts_last_quarter = np.vstack(tracts_last_quarter)\n",
    "    return pts, pts_last_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[pts, pts_last_quarter] = returnBundlePoints(gs_cst_right_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_gs_x = pd.DataFrame(np.transpose([pts[:,0], pts[:,2]]))\n",
    "DF_gs_x.rename(columns = lambda x: str(x), inplace=True)\n",
    "DF_gs_x.rename(columns={\"0\": \"X\"}, inplace=True) # rename a dfcolumn   \n",
    "DF_gs_x.rename(columns={\"1\": \"Y\"}, inplace=True) # rename a dfcolumn \n",
    "DF_gs_x\n",
    "\n",
    "ggplot(aes(x = 'X', y ='Y'),data=DF_gs_x) + \\\n",
    "    geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts = pts_last_quarter\n",
    "\n",
    "DF_gs_x = pd.DataFrame(np.transpose([pts[:,0], pts[:,2]]))\n",
    "DF_gs_x.rename(columns = lambda x: str(x), inplace=True)\n",
    "DF_gs_x.rename(columns={\"0\": \"X\"}, inplace=True) # rename a dfcolumn   \n",
    "DF_gs_x.rename(columns={\"1\": \"Y\"}, inplace=True) # rename a dfcolumn \n",
    "DF_gs_x\n",
    "\n",
    "ggplot(aes(x = 'X', y ='Y'),data=DF_gs_x) + \\\n",
    "    geom_point() \\\n",
    "    + xlim(-40, 80) \\\n",
    "    + ylim(-80, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gs_cst_fn = '/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/test_wmql/July31/Baseline_query_cc_3.vtp'\n",
    "# sr_cst_fn = '/scratch/TESTS/IpythonNotebook/20160615_HCPWF/mainWF/test_wmql/July31/IFFT_query_cc_3.vtp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def ComputeBhattacharyyaCoeficient(baseline_bundle, sr_bundle):\n",
    "#     import vtk\n",
    "#     import numpy as np\n",
    "#     ##\n",
    "#     def ReturnDistributionInEachCoordinate(bundle):\n",
    "#         from scipy import stats\n",
    "#         numPoints = bundle.GetNumberOfPoints()\n",
    "#         points = bundle.GetPoints()\n",
    "#         x_arr = np.array([points.GetPoint(i)[0] for i in xrange(numPoints)])\n",
    "#         y_arr = np.array([points.GetPoint(i)[1] for i in xrange(numPoints)])\n",
    "#         z_arr = np.array([points.GetPoint(i)[2] for i in xrange(numPoints)])\n",
    "#         x = np.linspace(x_arr.min(), x_arr.max(), 100)\n",
    "#         y = np.linspace(y_arr.min(), y_arr.max(), 100)\n",
    "#         z = np.linspace(z_arr.min(), z_arr.max(), 100)\n",
    "#         kde_x = stats.gaussian_kde(x_arr)\n",
    "#         kde_y = stats.gaussian_kde(y_arr)\n",
    "#         kde_z = stats.gaussian_kde(z_arr)\n",
    "#         p_x = kde_x(x)\n",
    "#         p_x = p_x/sum(p_x)\n",
    "#         p_y = kde_y(y)\n",
    "#         p_y = p_y/sum(p_y)\n",
    "#         p_z = kde_z(z)\n",
    "#         p_z = p_z/sum(p_z)\n",
    "#         return p_x, p_y, p_z\n",
    "#     ## read in each fiber bundle\n",
    "#     reader_gs = vtk.vtkXMLPolyDataReader()\n",
    "#     reader_gs.SetFileName(baseline_bundle)\n",
    "#     reader_gs.Update()\n",
    "#     gs = reader_gs.GetOutput()\n",
    "#     gs_bundle = reader_gs.GetOutput()\n",
    "#     #\n",
    "#     reader_sr = vtk.vtkXMLPolyDataReader()\n",
    "#     reader_sr.SetFileName(sr_bundle)\n",
    "#     reader_sr.Update()\n",
    "#     sr = reader_sr.GetOutput()\n",
    "#     ## Use ksdensity to estimate probability density function for the sample data in each coordinate\n",
    "#     [p_gs_x, p_gs_y, p_gs_z] = ReturnDistributionInEachCoordinate(gs)\n",
    "#     [p_sr_x, p_sr_y, p_sr_z] = ReturnDistributionInEachCoordinate(sr)\n",
    "#     BC = (1.0/3.0)*( np.sum(np.sqrt(p_gs_x * p_sr_x)) + np.sum(np.sqrt(p_gs_y * p_sr_y)) + np.sum(np.sqrt(p_gs_z * p_sr_z)) )\n",
    "#     return BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bc = ComputeBhattacharyyaCoeficient(gs_cst_fn,sr_cst_fn)\n",
    "# print(bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
